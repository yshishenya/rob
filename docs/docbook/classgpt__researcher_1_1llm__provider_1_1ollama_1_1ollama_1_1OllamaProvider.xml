<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<section xmlns="http://docbook.org/ns/docbook" version="5.0" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider" xml:lang="en-US">
<title>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider Class Reference</title>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary></indexterm>
Collaboration diagram for gpt_researcher.llm_provider.ollama.ollama.OllamaProvider:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider__coll__graph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
<simplesect>
    <title>Public Member Functions    </title>
        <itemizedlist>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a97b824af8393105e35c94f351d9228eb">__init__</link> (self, <link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9">model</link>, <link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738">temperature</link>, <link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a27d45ca589ace704c67a3192039fe0e7">max_tokens</link>)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abaa5642f4e4df0315f8ee291cebfb338">get_base_url</link> (self)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab60b0d1083b153b47fb6336a914edbe3">get_llm_model</link> (self)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abca636c4eebeec620a4392555613ff9b">get_chat_response</link> (self, messages, stream, websocket=None)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1acc5ec4a2e770daf8a88b0e41ee044c04">stream_response</link> (self, messages, websocket=None)</para>
</listitem>
        </itemizedlist>
</simplesect>
<simplesect>
    <title>Public Attributes    </title>
        <itemizedlist>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9">model</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738">temperature</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a27d45ca589ace704c67a3192039fe0e7">max_tokens</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477">base_url</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b">llm</link></para>
</listitem>
        </itemizedlist>
</simplesect>
<section>
<title>Constructor &amp; Destructor Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a97b824af8393105e35c94f351d9228eb"/><section>
    <title>__init__()</title>
<indexterm><primary>__init__</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>__init__</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.__init__ ( self,  model,  temperature,  max_tokens)</computeroutput></para></section>
</section>
<section>
<title>Member Function Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abaa5642f4e4df0315f8ee291cebfb338"/><section>
    <title>get_base_url()</title>
<indexterm><primary>get_base_url</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>get_base_url</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.get_base_url ( self)</computeroutput></para>
<para><literallayout><computeroutput>Gets the Ollama Base URL from the environment variable if defined otherwise use the default one
Returns:</computeroutput></literallayout> </para>
</section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abca636c4eebeec620a4392555613ff9b"/><section>
    <title>get_chat_response()</title>
<indexterm><primary>get_chat_response</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>get_chat_response</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.get_chat_response ( self,  messages,  stream,  websocket = <computeroutput>None</computeroutput>
)</computeroutput></para>Here is the call graph for this function:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_abca636c4eebeec620a4392555613ff9b_cgraph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
</section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab60b0d1083b153b47fb6336a914edbe3"/><section>
    <title>get_llm_model()</title>
<indexterm><primary>get_llm_model</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>get_llm_model</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.get_llm_model ( self)</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1acc5ec4a2e770daf8a88b0e41ee044c04"/><section>
    <title>stream_response()</title>
<indexterm><primary>stream_response</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>stream_response</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.stream_response ( self,  messages,  websocket = <computeroutput>None</computeroutput>
)</computeroutput></para>Here is the caller graph for this function:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_acc5ec4a2e770daf8a88b0e41ee044c04_icgraph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
</section>
</section>
<section>
<title>Member Data Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477"/><section>
    <title>base_url</title>
<indexterm><primary>base_url</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>base_url</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.base_url</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b"/><section>
    <title>llm</title>
<indexterm><primary>llm</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>llm</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.llm</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a27d45ca589ace704c67a3192039fe0e7"/><section>
    <title>max_tokens</title>
<indexterm><primary>max_tokens</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>max_tokens</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.max_tokens</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9"/><section>
    <title>model</title>
<indexterm><primary>model</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>model</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.model</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738"/><section>
    <title>temperature</title>
<indexterm><primary>temperature</primary><secondary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider</primary><secondary>temperature</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.ollama.ollama.OllamaProvider.temperature</computeroutput></para></section>
<para>
The documentation for this class was generated from the following file:</para>
/tmp/github_repos_arch_doc_gen/yshishenya/rob/gpt_researcher/llm_provider/ollama/<link linkend="_ollama_8py">ollama.py</link></section>
</section>
