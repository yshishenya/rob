<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<section xmlns="http://docbook.org/ns/docbook" version="5.0" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider" xml:lang="en-US">
<title>gpt_researcher.llm_provider.mistral.mistral.MistralProvider Class Reference</title>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary></indexterm>
Collaboration diagram for gpt_researcher.llm_provider.mistral.mistral.MistralProvider:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider__coll__graph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
<simplesect>
    <title>Public Member Functions    </title>
        <itemizedlist>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1af26c66bfb17195ed5c35cccfe6d1cd1a">__init__</link> (self, <link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a2a5d786261b6d470fffc4758cd1acd88">model</link>, <link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1ab85d58e96f26f27bf3b84e46b9fd184c">temperature</link>, <link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1aab3e3cb4d5f2cb0b3217074772edccde">max_tokens</link>)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1af3a489c41f7e00774f48fd25b77035dd">get_api_key</link> (self)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a2fbf90be0afcd22fffc64207b310b2cc">get_llm_model</link> (self)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a61da1b8639a70293d3f60a3674ccbef7">get_chat_response</link> (self, messages, stream, websocket=None)</para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1ad46ecf3c0c6e62502709cdf36b783fb6">stream_response</link> (self, messages, websocket=None)</para>
</listitem>
        </itemizedlist>
</simplesect>
<simplesect>
    <title>Public Attributes    </title>
        <itemizedlist>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a2a5d786261b6d470fffc4758cd1acd88">model</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1ab85d58e96f26f27bf3b84e46b9fd184c">temperature</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1aab3e3cb4d5f2cb0b3217074772edccde">max_tokens</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1abd922b050c1302c18b04b4a459067e0b">api_key</link></para>
</listitem>
            <listitem><para><link linkend="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a24f3c3355f5ee04c048a91142f2867ff">llm</link></para>
</listitem>
        </itemizedlist>
</simplesect>
<section>
<title>Constructor &amp; Destructor Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1af26c66bfb17195ed5c35cccfe6d1cd1a"/><section>
    <title>__init__()</title>
<indexterm><primary>__init__</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>__init__</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.__init__ ( self,  model,  temperature,  max_tokens)</computeroutput></para></section>
</section>
<section>
<title>Member Function Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1af3a489c41f7e00774f48fd25b77035dd"/><section>
    <title>get_api_key()</title>
<indexterm><primary>get_api_key</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>get_api_key</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.get_api_key ( self)</computeroutput></para>
<para><literallayout><computeroutput>Gets the OpenAI API key
Returns:</computeroutput></literallayout> </para>
</section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a61da1b8639a70293d3f60a3674ccbef7"/><section>
    <title>get_chat_response()</title>
<indexterm><primary>get_chat_response</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>get_chat_response</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.get_chat_response ( self,  messages,  stream,  websocket = <computeroutput>None</computeroutput>
)</computeroutput></para>Here is the call graph for this function:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_a61da1b8639a70293d3f60a3674ccbef7_cgraph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
</section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a2fbf90be0afcd22fffc64207b310b2cc"/><section>
    <title>get_llm_model()</title>
<indexterm><primary>get_llm_model</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>get_llm_model</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.get_llm_model ( self)</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1ad46ecf3c0c6e62502709cdf36b783fb6"/><section>
    <title>stream_response()</title>
<indexterm><primary>stream_response</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>stream_response</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.stream_response ( self,  messages,  websocket = <computeroutput>None</computeroutput>
)</computeroutput></para>Here is the caller graph for this function:<para>
    <informalfigure>
        <mediaobject>
            <imageobject>
                <imagedata width="50%" align="center" valign="middle" scalefit="0" fileref="classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_ad46ecf3c0c6e62502709cdf36b783fb6_icgraph.svg"></imagedata>
            </imageobject>
        </mediaobject>
    </informalfigure>
</para>
</section>
</section>
<section>
<title>Member Data Documentation</title>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1abd922b050c1302c18b04b4a459067e0b"/><section>
    <title>api_key</title>
<indexterm><primary>api_key</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>api_key</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.api_key</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a24f3c3355f5ee04c048a91142f2867ff"/><section>
    <title>llm</title>
<indexterm><primary>llm</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>llm</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.llm</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1aab3e3cb4d5f2cb0b3217074772edccde"/><section>
    <title>max_tokens</title>
<indexterm><primary>max_tokens</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>max_tokens</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.max_tokens</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1a2a5d786261b6d470fffc4758cd1acd88"/><section>
    <title>model</title>
<indexterm><primary>model</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>model</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.model</computeroutput></para></section>
<anchor xml:id="_classgpt__researcher_1_1llm__provider_1_1mistral_1_1mistral_1_1MistralProvider_1ab85d58e96f26f27bf3b84e46b9fd184c"/><section>
    <title>temperature</title>
<indexterm><primary>temperature</primary><secondary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</secondary></indexterm>
<indexterm><primary>gpt_researcher.llm_provider.mistral.mistral.MistralProvider</primary><secondary>temperature</secondary></indexterm>
<para><computeroutput>gpt_researcher.llm_provider.mistral.mistral.MistralProvider.temperature</computeroutput></para></section>
<para>
The documentation for this class was generated from the following file:</para>
/tmp/github_repos_arch_doc_gen/yshishenya/rob/gpt_researcher/llm_provider/mistral/<link linkend="_mistral_8py">mistral.py</link></section>
</section>
