<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.10.0" xml:lang="en-US">
  <compounddef id="llm_8py" kind="file" language="Python">
    <compoundname>llm.py</compoundname>
    <innernamespace refid="namespacegpt__researcher">gpt_researcher</innernamespace>
    <innernamespace refid="namespacegpt__researcher_1_1utils">gpt_researcher::utils</innernamespace>
    <innernamespace refid="namespacegpt__researcher_1_1utils_1_1llm">gpt_researcher::utils::llm</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1" refid="namespacegpt__researcher_1_1utils_1_1llm" refkind="compound"><highlight class="comment">#<sp/>libraries</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>__future__<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>annotations</highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>json</highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>logging</highlight></codeline>
<codeline lineno="6"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>typing<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Optional,<sp/>Any,<sp/>Dict</highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight></codeline>
<codeline lineno="8"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>colorama<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Fore,<sp/>Style</highlight></codeline>
<codeline lineno="9"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>fastapi<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>WebSocket</highlight></codeline>
<codeline lineno="10"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>langchain.output_parsers<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>PydanticOutputParser</highlight></codeline>
<codeline lineno="11"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>langchain.prompts<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>PromptTemplate</highlight></codeline>
<codeline lineno="12"><highlight class="normal"></highlight></codeline>
<codeline lineno="13"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/><ref refid="namespacegpt__researcher_1_1master_1_1prompts" kindref="compound">gpt_researcher.master.prompts</ref><sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>auto_agent_instructions,<sp/>generate_subtopics_prompt</highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>.costs<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>estimate_llm_cost</highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>.validators<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Subtopics</highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"></highlight></codeline>
<codeline lineno="18" refid="namespacegpt__researcher_1_1utils_1_1llm_1a350bb4294397495c506426a2caad2b31" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="namespacegpt__researcher_1_1utils_1_1llm_1a350bb4294397495c506426a2caad2b31" kindref="member">get_llm</ref>(llm_provider,<sp/>**kwargs):</highlight></codeline>
<codeline lineno="19"><highlight class="normal"><sp/><sp/><sp/><sp/>match<sp/>llm_provider:</highlight></codeline>
<codeline lineno="20"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;openai&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>OpenAIProvider</highlight></codeline>
<codeline lineno="22"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>OpenAIProvider</highlight></codeline>
<codeline lineno="23"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;azureopenai&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="24"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>AzureOpenAIProvider</highlight></codeline>
<codeline lineno="25"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>AzureOpenAIProvider</highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;google&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>GoogleProvider</highlight></codeline>
<codeline lineno="28"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>GoogleProvider</highlight></codeline>
<codeline lineno="29"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;ollama&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="30"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>OllamaProvider</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>OllamaProvider</highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;groq&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>GroqProvider</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>GroqProvider</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;together&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>TogetherProvider</highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>TogetherProvider</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;huggingface&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="39"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>HugginFaceProvider</highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>HugginFaceProvider</highlight></codeline>
<codeline lineno="41"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;mistral&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="42"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>MistralProvider</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>MistralProvider</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/></highlight><highlight class="stringliteral">&quot;anthropic&quot;</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>..llm_provider<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>AnthropicProvider</highlight></codeline>
<codeline lineno="46"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>=<sp/>AnthropicProvider</highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Generic<sp/>case<sp/>for<sp/>all<sp/>other<sp/>providers<sp/>supported<sp/>by<sp/>Langchain</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="48"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>case<sp/>_:</highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/><ref refid="namespacegpt__researcher_1_1llm__provider" kindref="compound">gpt_researcher.llm_provider</ref><sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>GenericLLMProvider</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>GenericLLMProvider.from_provider(llm_provider,<sp/>**kwargs)</highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight></codeline>
<codeline lineno="52"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>llm_provider(**kwargs)</highlight></codeline>
<codeline lineno="53"><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight></codeline>
<codeline lineno="55" refid="namespacegpt__researcher_1_1utils_1_1llm_1aabaadb598e9e86c6e4a0c50627463b95" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">async<sp/>def<sp/></highlight><highlight class="normal"><ref refid="namespacegpt__researcher_1_1utils_1_1llm_1aabaadb598e9e86c6e4a0c50627463b95" kindref="member">create_chat_completion</ref>(</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>messages:<sp/>list,<sp/><sp/></highlight><highlight class="comment">#<sp/>type:<sp/>ignore</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>model:<sp/>Optional[str]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature:<sp/>float<sp/>=<sp/>1.0,</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_tokens:<sp/>Optional[int]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider:<sp/>Optional[str]<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>stream:<sp/>Optional[bool]<sp/>=<sp/></highlight><highlight class="keyword">False</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>websocket:<sp/>WebSocket<sp/>|<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_kwargs:<sp/>Dict[str,<sp/>Any]<sp/>|<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">,</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cost_callback:<sp/>callable<sp/>=<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="65"><highlight class="normal">)<sp/>-&gt;<sp/>str:</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;Create<sp/>a<sp/>chat<sp/>completion<sp/>using<sp/>the<sp/>OpenAI<sp/>API</highlight></codeline>
<codeline lineno="67"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>Args:</highlight></codeline>
<codeline lineno="68"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>messages<sp/>(list[dict[str,<sp/>str]]):<sp/>The<sp/>messages<sp/>to<sp/>send<sp/>to<sp/>the<sp/>chat<sp/>completion</highlight></codeline>
<codeline lineno="69"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>model<sp/>(str,<sp/>optional):<sp/>The<sp/>model<sp/>to<sp/>use.<sp/>Defaults<sp/>to<sp/>None.</highlight></codeline>
<codeline lineno="70"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature<sp/>(float,<sp/>optional):<sp/>The<sp/>temperature<sp/>to<sp/>use.<sp/>Defaults<sp/>to<sp/>0.9.</highlight></codeline>
<codeline lineno="71"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_tokens<sp/>(int,<sp/>optional):<sp/>The<sp/>max<sp/>tokens<sp/>to<sp/>use.<sp/>Defaults<sp/>to<sp/>None.</highlight></codeline>
<codeline lineno="72"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>stream<sp/>(bool,<sp/>optional):<sp/>Whether<sp/>to<sp/>stream<sp/>the<sp/>response.<sp/>Defaults<sp/>to<sp/>False.</highlight></codeline>
<codeline lineno="73"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_provider<sp/>(str,<sp/>optional):<sp/>The<sp/>LLM<sp/>Provider<sp/>to<sp/>use.</highlight></codeline>
<codeline lineno="74"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>webocket<sp/>(WebSocket):<sp/>The<sp/>websocket<sp/>used<sp/>in<sp/>the<sp/>currect<sp/>request,</highlight></codeline>
<codeline lineno="75"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cost_callback:<sp/>Callback<sp/>function<sp/>for<sp/>updating<sp/>cost</highlight></codeline>
<codeline lineno="76"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="77"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>str:<sp/>The<sp/>response<sp/>from<sp/>the<sp/>chat<sp/>completion</highlight></codeline>
<codeline lineno="78"><highlight class="stringliteral"><sp/><sp/><sp/><sp/>&quot;&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="79"><highlight class="normal"></highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>validate<sp/>input</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>model<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(</highlight><highlight class="stringliteral">&quot;Model<sp/>cannot<sp/>be<sp/>None&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>max_tokens<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">and</highlight><highlight class="normal"><sp/>max_tokens<sp/>&gt;<sp/>8001:</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>ValueError(</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>f</highlight><highlight class="stringliteral">&quot;Max<sp/>tokens<sp/>cannot<sp/>be<sp/>more<sp/>than<sp/>8001,<sp/>but<sp/>got<sp/>{max_tokens}&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="86"><highlight class="normal"></highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Get<sp/>the<sp/>provider<sp/>from<sp/>supported<sp/>providers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/><sp/><sp/>provider<sp/>=<sp/><ref refid="namespacegpt__researcher_1_1utils_1_1llm_1a350bb4294397495c506426a2caad2b31" kindref="member">get_llm</ref>(llm_provider,<sp/>model=model,<sp/>temperature=temperature,<sp/>max_tokens=max_tokens,<sp/>**llm_kwargs)</highlight></codeline>
<codeline lineno="89"><highlight class="normal"></highlight></codeline>
<codeline lineno="90"><highlight class="normal"><sp/><sp/><sp/><sp/>response<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="91"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>create<sp/>response</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="92"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>_<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>range(10):<sp/><sp/></highlight><highlight class="comment">#<sp/>maximum<sp/>of<sp/>10<sp/>attempts</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="93"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>response<sp/>=<sp/>await<sp/>provider.get_chat_response(</highlight></codeline>
<codeline lineno="94"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>messages,<sp/>stream,<sp/>websocket</highlight></codeline>
<codeline lineno="95"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="96"><highlight class="normal"></highlight></codeline>
<codeline lineno="97"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>cost_callback:</highlight></codeline>
<codeline lineno="98"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm_costs<sp/>=<sp/>estimate_llm_cost(str(messages),<sp/>response)</highlight></codeline>
<codeline lineno="99"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>cost_callback(llm_costs)</highlight></codeline>
<codeline lineno="100"><highlight class="normal"></highlight></codeline>
<codeline lineno="101"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>response</highlight></codeline>
<codeline lineno="102"><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"><sp/><sp/><sp/><sp/>logging.error(f</highlight><highlight class="stringliteral">&quot;Failed<sp/>to<sp/>get<sp/>response<sp/>from<sp/>{llm_provider}<sp/>API&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">raise</highlight><highlight class="normal"><sp/>RuntimeError(f</highlight><highlight class="stringliteral">&quot;Failed<sp/>to<sp/>get<sp/>response<sp/>from<sp/>{llm_provider}<sp/>API&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="105"><highlight class="normal"></highlight></codeline>
<codeline lineno="106"><highlight class="normal"></highlight></codeline>
<codeline lineno="107" refid="namespacegpt__researcher_1_1utils_1_1llm_1a3125e642ba0eba1562845ff7d15ecb08" refkind="member"><highlight class="normal"></highlight><highlight class="keyword">async<sp/>def<sp/></highlight><highlight class="normal"><ref refid="namespacegpt__researcher_1_1utils_1_1llm_1a3125e642ba0eba1562845ff7d15ecb08" kindref="member">construct_subtopics</ref>(task:<sp/>str,<sp/>data:<sp/>str,<sp/>config,<sp/>subtopics:<sp/>list<sp/>=<sp/>[])<sp/>-&gt;<sp/>list:</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>parser<sp/>=<sp/>PydanticOutputParser(pydantic_object=Subtopics)</highlight></codeline>
<codeline lineno="110"><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>prompt<sp/>=<sp/>PromptTemplate(</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>template=generate_subtopics_prompt(),</highlight></codeline>
<codeline lineno="113"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>input_variables=[</highlight><highlight class="stringliteral">&quot;task&quot;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&quot;data&quot;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&quot;subtopics&quot;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&quot;max_subtopics&quot;</highlight><highlight class="normal">],</highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>partial_variables={</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;format_instructions&quot;</highlight><highlight class="normal">:<sp/>parser.get_format_instructions()},</highlight></codeline>
<codeline lineno="116"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="117"><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>print(f</highlight><highlight class="stringliteral">&quot;\n🤖<sp/>Calling<sp/>{config.smart_llm_model}...\n&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="119"><highlight class="normal"></highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature<sp/>=<sp/>config.temperature</highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>temperature<sp/>=<sp/>0<sp/>#<sp/>Note:<sp/>temperature<sp/>throughout<sp/>the<sp/>code<sp/>base<sp/>is<sp/>currently<sp/>set<sp/>to<sp/>Zero</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>provider<sp/>=<sp/><ref refid="namespacegpt__researcher_1_1utils_1_1llm_1a350bb4294397495c506426a2caad2b31" kindref="member">get_llm</ref>(config.llm_provider,<sp/>model=config.smart_llm_model,<sp/>temperature=temperature,<sp/>max_tokens=config.smart_token_limit,<sp/>**config.llm_kwargs)</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>model<sp/>=<sp/>provider.llm</highlight></codeline>
<codeline lineno="124"><highlight class="normal"></highlight></codeline>
<codeline lineno="125"><highlight class="normal"></highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>chain<sp/>=<sp/>prompt<sp/>|<sp/>model<sp/>|<sp/>parser</highlight></codeline>
<codeline lineno="127"><highlight class="normal"></highlight></codeline>
<codeline lineno="128"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output<sp/>=<sp/>chain.invoke({</highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;task&quot;</highlight><highlight class="normal">:<sp/>task,</highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;data&quot;</highlight><highlight class="normal">:<sp/>data,</highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;subtopics&quot;</highlight><highlight class="normal">:<sp/>subtopics,</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;max_subtopics&quot;</highlight><highlight class="normal">:<sp/>config.max_subtopics</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>})</highlight></codeline>
<codeline lineno="134"><highlight class="normal"></highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>output</highlight></codeline>
<codeline lineno="136"><highlight class="normal"></highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">except</highlight><highlight class="normal"><sp/>Exception<sp/></highlight><highlight class="keyword">as</highlight><highlight class="normal"><sp/>e:</highlight></codeline>
<codeline lineno="138"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>print(</highlight><highlight class="stringliteral">&quot;Exception<sp/>in<sp/>parsing<sp/>subtopics<sp/>:<sp/>&quot;</highlight><highlight class="normal">,<sp/>e)</highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>subtopics</highlight></codeline>
    </programlisting>
    <location file="/tmp/github_repos_arch_doc_gen/yshishenya/rob/gpt_researcher/utils/llm.py"/>
  </compounddef>
</doxygen>
