<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.10.0" xml:lang="en-US">
  <compounddef id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph" kind="page">
    <compoundname>md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph</compoundname>
    <title>LangGraph</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para><anchor id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md99"/><ulink url="https://python.langchain.com/docs/langgraph">LangGraph</ulink> is a library for building stateful, multi-actor applications with LLMs. This example uses Langgraph to automate the process of an in depth research on any given topic.</para>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md100">
<title>Use case</title><para>By using Langgraph, the research process can be significantly improved in depth and quality by leveraging multiple agents with specialized skills. Inspired by the recent <ulink url="https://arxiv.org/abs/2402.14207">STORM</ulink> paper, this example showcases how a team of AI agents can work together to conduct research on a given topic, from planning to publication.</para>
<para>An average run generates a 5-6 page research report in multiple formats such as PDF, Docx and Markdown.</para>
</sect1>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md101">
<title>The Multi Agent Team</title><para>The research team is made up of 7 AI agents:<itemizedlist>
<listitem><para><bold>Chief Editor</bold> - Oversees the research process and manages the team. This is the &quot;master&quot; agent that coordinates the other agents using Langgraph.</para>
</listitem><listitem><para><bold>Researcher</bold> (gpt-researcher) - A specialized autonomous agent that conducts in depth research on a given topic.</para>
</listitem><listitem><para><bold>Editor</bold> - Responsible for planning the research outline and structure.</para>
</listitem><listitem><para><bold>Reviewer</bold> - Validates the correctness of the research results given a set of criteria.</para>
</listitem><listitem><para><bold>Revisor</bold> - Revises the research results based on the feedback from the reviewer.</para>
</listitem><listitem><para><bold>Writer</bold> - Responsible for compiling and writing the final report.</para>
</listitem><listitem><para><bold>Publisher</bold> - Responsible for publishing the final report in various formats.</para>
</listitem></itemizedlist>
</para>
</sect1>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md102">
<title>How it works</title><para>Generally, the process is based on the following stages:<orderedlist>
<listitem><para>Planning stage</para>
</listitem><listitem><para>Data collection and analysis</para>
</listitem><listitem><para>Review and revision</para>
</listitem><listitem><para>Writing and submission</para>
</listitem><listitem><para>Publication</para>
</listitem></orderedlist>
</para>
<sect2 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md103">
<title>Architecture</title><para> <image type="html" name="https://cowriter-images.s3.amazonaws.com/gptr-langgraph-architecture.png" inline="yes"></image>
  <linebreak/>
</para>
</sect2>
<sect2 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md104">
<title>Steps</title><para>More specifically (as seen in the architecture diagram) the process is as follows:<itemizedlist>
<listitem><para>Browser (gpt-researcher) - Browses the internet for initial research based on the given research task.</para>
</listitem><listitem><para>Editor - Plans the report outline and structure based on the initial research.</para>
</listitem><listitem><para>For each outline topic (in parallel):<itemizedlist>
<listitem><para>Researcher (gpt-researcher) - Runs an in depth research on the subtopics and writes a draft.</para>
</listitem><listitem><para>Reviewer - Validates the correctness of the draft given a set of criteria and provides feedback.</para>
</listitem><listitem><para>Revisor - Revises the draft until it is satisfactory based on the reviewer feedback.</para>
</listitem></itemizedlist>
</para>
</listitem><listitem><para>Writer - Compiles and writes the final report including an introduction, conclusion and references section from the given research findings.</para>
</listitem><listitem><para>Publisher - Publishes the final report to multi formats such as PDF, Docx, Markdown, etc.</para>
</listitem></itemizedlist>
</para>
</sect2>
</sect1>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md105">
<title>How to run</title><para><orderedlist>
<listitem><para>Install required packages: <programlisting filename=".bash"><codeline><highlight class="normal">pip<sp/>install<sp/>-r<sp/>requirements.txt</highlight></codeline>
</programlisting></para>
</listitem><listitem><para>Update env variables <programlisting filename=".bash"><codeline><highlight class="normal">export<sp/>OPENAI_API_KEY={Your<sp/>OpenAI<sp/>API<sp/>Key<sp/>here}</highlight></codeline>
<codeline><highlight class="normal">export<sp/>TAVILY_API_KEY={Your<sp/>Tavily<sp/>API<sp/>Key<sp/>here}</highlight></codeline>
</programlisting></para>
</listitem></orderedlist>
<orderedlist>
<listitem><para>Run the application: <programlisting filename=".bash"><codeline><highlight class="normal">python<sp/>main.py</highlight></codeline>
</programlisting></para>
</listitem></orderedlist>
</para>
</sect1>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md106">
<title>Usage</title><para>To change the research query and customize the report, edit the <computeroutput>task.json</computeroutput> file in the main directory. </para>
<sect3 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md107">
<title>Task.json contains the following fields:</title><para><itemizedlist>
<listitem><para><computeroutput>query</computeroutput> - The research query or task.</para>
</listitem><listitem><para><computeroutput>model</computeroutput> - The OpenAI LLM to use for the agents.</para>
</listitem><listitem><para><computeroutput>max_sections</computeroutput> - The maximum number of sections in the report. Each section is a subtopic of the research query.</para>
</listitem><listitem><para><computeroutput>publish_formats</computeroutput> - The formats to publish the report in. The reports will be written in the <computeroutput>output</computeroutput> directory.</para>
</listitem><listitem><para><computeroutput>source</computeroutput> - The location from which to conduct the research. Options: <computeroutput>web</computeroutput> or <computeroutput>local</computeroutput>. For local, please add <computeroutput>DOC_PATH</computeroutput> env var.</para>
</listitem><listitem><para><computeroutput>follow_guidelines</computeroutput> - If true, the research report will follow the guidelines below. It will take longer to complete. If false, the report will be generated faster but may not follow the guidelines.</para>
</listitem><listitem><para><computeroutput>guidelines</computeroutput> - A list of guidelines that the report must follow.</para>
</listitem><listitem><para><computeroutput>verbose</computeroutput> - If true, the application will print detailed logs to the console.</para>
</listitem></itemizedlist>
</para>
</sect3>
<sect3 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md108">
<title>For example:</title><para><programlisting filename=".json"><codeline><highlight class="normal">{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;query&quot;:<sp/>&quot;Is<sp/>AI<sp/>in<sp/>a<sp/>hype<sp/>cycle?&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;model&quot;:<sp/>&quot;gpt-4o&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;max_sections&quot;:<sp/>3,<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;publish_formats&quot;:<sp/>{<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;markdown&quot;:<sp/>true,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;pdf&quot;:<sp/>true,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;docx&quot;:<sp/>true</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>},</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;source&quot;:<sp/>&quot;web&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;follow_guidelines&quot;:<sp/>true,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;guidelines&quot;:<sp/>[</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;The<sp/>report<sp/>MUST<sp/>fully<sp/>answer<sp/>the<sp/>original<sp/>question&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;The<sp/>report<sp/>MUST<sp/>be<sp/>written<sp/>in<sp/>apa<sp/>format&quot;,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>&quot;The<sp/>report<sp/>MUST<sp/>be<sp/>written<sp/>in<sp/>english&quot;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>],</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>&quot;verbose&quot;:<sp/>true</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
</programlisting></para>
</sect3>
</sect1>
<sect1 id="md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2langgraph_1autotoc_md109">
<title>To Deploy</title><para><programlisting filename=".shell"><codeline><highlight class="normal">pip<sp/>install<sp/>langgraph-cli</highlight></codeline>
<codeline><highlight class="normal">langgraph<sp/>up</highlight></codeline>
</programlisting></para>
<para>From there, see documentation <ulink url="https://github.com/langchain-ai/langgraph-example">here</ulink> on how to use the streaming and async endpoints, as well as the playground. </para>
</sect1>
    </detaileddescription>
    <location file="/tmp/github_repos_arch_doc_gen/yshishenya/rob/docs/docs/gpt-researcher/langgraph.md"/>
  </compounddef>
</doxygen>
