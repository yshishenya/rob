<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.10.0" xml:lang="en-US">
  <compounddef id="ollama_8py" kind="file" language="Python">
    <compoundname>ollama.py</compoundname>
    <innerclass refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider" prot="public">gpt_researcher::llm_provider::ollama::ollama::OllamaProvider</innerclass>
    <innernamespace refid="namespacegpt__researcher">gpt_researcher</innernamespace>
    <innernamespace refid="namespacegpt__researcher_1_1llm__provider">gpt_researcher::llm_provider</innernamespace>
    <innernamespace refid="namespacegpt__researcher_1_1llm__provider_1_1ollama">gpt_researcher::llm_provider::ollama</innernamespace>
    <innernamespace refid="namespacegpt__researcher_1_1llm__provider_1_1ollama_1_1ollama">gpt_researcher::llm_provider::ollama::ollama</innernamespace>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
    </detaileddescription>
    <programlisting>
<codeline lineno="1" refid="namespacegpt__researcher_1_1llm__provider_1_1ollama" refkind="compound"><highlight class="keyword">import</highlight><highlight class="normal"><sp/>os</highlight></codeline>
<codeline lineno="2"><highlight class="normal"></highlight></codeline>
<codeline lineno="3"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>colorama<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>Fore,<sp/>Style</highlight></codeline>
<codeline lineno="4"><highlight class="normal"></highlight><highlight class="keyword">from</highlight><highlight class="normal"><sp/>langchain_community.chat_models<sp/></highlight><highlight class="keyword">import</highlight><highlight class="normal"><sp/>ChatOllama</highlight></codeline>
<codeline lineno="5"><highlight class="normal"></highlight></codeline>
<codeline lineno="6" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">class<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider" kindref="compound">OllamaProvider</ref>:</highlight></codeline>
<codeline lineno="7"><highlight class="normal"></highlight></codeline>
<codeline lineno="8" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a97b824af8393105e35c94f351d9228eb" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a97b824af8393105e35c94f351d9228eb" kindref="member">__init__</ref>(</highlight></codeline>
<codeline lineno="9"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self,</highlight></codeline>
<codeline lineno="10"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>model,</highlight></codeline>
<codeline lineno="11"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature,</highlight></codeline>
<codeline lineno="12"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>max_tokens</highlight></codeline>
<codeline lineno="13"><highlight class="normal"><sp/><sp/><sp/><sp/>):</highlight></codeline>
<codeline lineno="14" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9" kindref="member">model</ref><sp/>=<sp/>model</highlight></codeline>
<codeline lineno="15" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738" kindref="member">temperature</ref><sp/>=<sp/>temperature</highlight></codeline>
<codeline lineno="16" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a27d45ca589ace704c67a3192039fe0e7" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a27d45ca589ace704c67a3192039fe0e7" kindref="member">max_tokens</ref><sp/>=<sp/>max_tokens</highlight></codeline>
<codeline lineno="17" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477" kindref="member">base_url</ref><sp/>=<sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abaa5642f4e4df0315f8ee291cebfb338" kindref="member">get_base_url</ref>()</highlight></codeline>
<codeline lineno="18" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b" kindref="member">llm</ref><sp/>=<sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab60b0d1083b153b47fb6336a914edbe3" kindref="member">get_llm_model</ref>()</highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abaa5642f4e4df0315f8ee291cebfb338" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abaa5642f4e4df0315f8ee291cebfb338" kindref="member">get_base_url</ref>(self):</highlight></codeline>
<codeline lineno="21"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="stringliteral">&quot;&quot;&quot;</highlight></codeline>
<codeline lineno="22"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Gets<sp/>the<sp/>Ollama<sp/>Base<sp/>URL<sp/>from<sp/>the<sp/>environment<sp/>variable<sp/>if<sp/>defined<sp/>otherwise<sp/>use<sp/>the<sp/>default<sp/>one</highlight></codeline>
<codeline lineno="23"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Returns:</highlight></codeline>
<codeline lineno="24"><highlight class="stringliteral"></highlight></codeline>
<codeline lineno="25"><highlight class="stringliteral"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&quot;&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="26"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>base_url<sp/>=<sp/>os.environ.get(</highlight><highlight class="stringliteral">&quot;OLLAMA_BASE_URL&quot;</highlight><highlight class="normal">,<sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="27"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>base_url</highlight></codeline>
<codeline lineno="28"><highlight class="normal"></highlight></codeline>
<codeline lineno="29"><highlight class="normal"></highlight></codeline>
<codeline lineno="30" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab60b0d1083b153b47fb6336a914edbe3" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">def<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab60b0d1083b153b47fb6336a914edbe3" kindref="member">get_llm_model</ref>(self):</highlight></codeline>
<codeline lineno="31"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Initializing<sp/>the<sp/>chat<sp/>model</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="32"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm<sp/>=<sp/>ChatOllama(</highlight></codeline>
<codeline lineno="33"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>model=self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1ab847ab673b47eff2b2668b17d1e409b9" kindref="member">model</ref>,</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>temperature=self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a75ef1fe2b40db6e77bea1efe8598e738" kindref="member">temperature</ref>,</highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>keep_alive=</highlight><highlight class="keywordtype">None</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>)</highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477" kindref="member">base_url</ref>:</highlight></codeline>
<codeline lineno="38"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>llm.base_url<sp/>=<sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a7adaf9267389bec080606d2a4a1bf477" kindref="member">base_url</ref></highlight></codeline>
<codeline lineno="39"><highlight class="normal"></highlight></codeline>
<codeline lineno="40"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>llm</highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abca636c4eebeec620a4392555613ff9b" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">async<sp/>def<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1abca636c4eebeec620a4392555613ff9b" kindref="member">get_chat_response</ref>(self,<sp/>messages,<sp/>stream,<sp/>websocket=None):</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/>stream:</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Getting<sp/>output<sp/>from<sp/>the<sp/>model<sp/>chain<sp/>using<sp/>ainvoke<sp/>for<sp/>asynchronous<sp/>invoking</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output<sp/>=<sp/>await<sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b" kindref="member">llm</ref>.ainvoke(messages)</highlight></codeline>
<codeline lineno="46"><highlight class="normal"></highlight></codeline>
<codeline lineno="47"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>output.content</highlight></codeline>
<codeline lineno="48"><highlight class="normal"></highlight></codeline>
<codeline lineno="49"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="50"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>await<sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1acc5ec4a2e770daf8a88b0e41ee044c04" kindref="member">stream_response</ref>(messages,<sp/>websocket)</highlight></codeline>
<codeline lineno="51"><highlight class="normal"></highlight></codeline>
<codeline lineno="52" refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1acc5ec4a2e770daf8a88b0e41ee044c04" refkind="member"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">async<sp/>def<sp/></highlight><highlight class="normal"><ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1acc5ec4a2e770daf8a88b0e41ee044c04" kindref="member">stream_response</ref>(self,<sp/>messages,<sp/>websocket=None):</highlight></codeline>
<codeline lineno="53"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>paragraph<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>response<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="55"><highlight class="normal"></highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">#<sp/>Streaming<sp/>the<sp/>response<sp/>using<sp/>the<sp/>chain<sp/>astream<sp/>method<sp/>from<sp/>langchain</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="57"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">async</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>chunk<sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>self.<ref refid="classgpt__researcher_1_1llm__provider_1_1ollama_1_1ollama_1_1OllamaProvider_1a8c2509e16a319613e2142a5e78164e3b" kindref="member">llm</ref>.astream(messages):</highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>content<sp/>=<sp/>chunk.content</highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>content<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>response<sp/>+=<sp/>content</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>paragraph<sp/>+=<sp/>content</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/></highlight><highlight class="stringliteral">&quot;\n&quot;</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">in</highlight><highlight class="normal"><sp/>paragraph:</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>websocket<sp/></highlight><highlight class="keywordflow">is</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordflow">not</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">None</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="64"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>await<sp/>websocket.send_json({</highlight><highlight class="stringliteral">&quot;type&quot;</highlight><highlight class="normal">:<sp/></highlight><highlight class="stringliteral">&quot;report&quot;</highlight><highlight class="normal">,<sp/></highlight><highlight class="stringliteral">&quot;output&quot;</highlight><highlight class="normal">:<sp/>paragraph})</highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal">:</highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>print(f</highlight><highlight class="stringliteral">&quot;{Fore.GREEN}{paragraph}{Style.RESET_ALL}&quot;</highlight><highlight class="normal">)</highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>paragraph<sp/>=<sp/></highlight><highlight class="stringliteral">&quot;&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"></highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>response</highlight></codeline>
    </programlisting>
    <location file="/tmp/github_repos_arch_doc_gen/yshishenya/rob/gpt_researcher/llm_provider/ollama/ollama.py"/>
  </compounddef>
</doxygen>
