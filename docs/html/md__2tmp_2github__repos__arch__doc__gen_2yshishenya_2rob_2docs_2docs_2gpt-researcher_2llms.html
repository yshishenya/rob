<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.10.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- BEGIN opengraph metadata -->
<meta property="og:title" content="Doxygen Awesome" />
<meta property="og:image" content="https://repository-images.githubusercontent.com/348492097/4f16df80-88fb-11eb-9d31-4015ff22c452" />
<meta property="og:description" content="Custom CSS theme for doxygen html-documentation with lots of customization parameters." />
<meta property="og:url" content="https://jothepro.github.io/doxygen-awesome-css/" />
<!-- END opengraph metadata -->
<!-- BEGIN twitter metadata -->
<meta name="twitter:image:src" content="https://repository-images.githubusercontent.com/348492097/4f16df80-88fb-11eb-9d31-4015ff22c452" />
<meta name="twitter:title" content="Doxygen Awesome" />
<meta name="twitter:description" content="Custom CSS theme for doxygen html-documentation with lots of customization parameters." />
<!-- END twitter metadata -->
<title>rob: Configure LLM</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" type="image/svg+xml" href="logo.drawio.svg"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript" src="doxygen-awesome-fragment-copy-button.js"></script>
<script type="text/javascript" src="doxygen-awesome-paragraph-link.js"></script>
<script type="text/javascript" src="doxygen-awesome-interactive-toc.js"></script>
<script type="text/javascript" src="doxygen-awesome-tabs.js"></script>
<script type="text/javascript" src="toggle-alternative-theme.js"></script>
<script type="text/javascript">
    DoxygenAwesomeFragmentCopyButton.init()
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeParagraphLink.init()
    DoxygenAwesomeInteractiveToc.init()
    DoxygenAwesomeTabs.init()
</script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- https://tholman.com/github-corners/ -->
<a href="https://github.com/jothepro/doxygen-awesome-css" class="github-corner" title="View source on GitHub" target="_blank" rel="noopener noreferrer">
    <svg viewBox="0 0 250 250" width="40" height="40" style="position: absolute; top: 0; border: 0; right: 0; z-index: 99;" aria-hidden="true">
    <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">rob
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part --><!-- Generated by Doxygen 1.10.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('md__2tmp_2github__repos__arch__doc__gen_2yshishenya_2rob_2docs_2docs_2gpt-researcher_2llms.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Configure LLM</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md110"></a>As described in the <a href="/docs/gpt-researcher/config">introduction</a>, the default LLM is OpenAI due to its superior performance and speed. With that said, GPT Researcher supports various open/closed source LLMs, and you can easily switch between them by adding the <code>LLM_PROVIDER</code> env variable and corresponding configuration params. Current supported LLMs are <code>openai</code>, <code>google</code> (gemini), <code>azureopenai</code>, <code>ollama</code>, <code>anthropic</code>, <code>mistral</code>, <code>huggingface</code> and <code>groq</code>.</p>
<p>Using any model will require at least updating the <code>LLM_PROVIDER</code> param and passing the LLM provider API Key. You might also need to update the <code>SMART_LLM_MODEL</code> and <code>FAST_LLM_MODEL</code> env vars. To learn more about support customization options see <a href="/gpt-researcher/config">here</a>.</p>
<p><b>Please note</b>: GPT Researcher is optimized and heavily tested on GPT models. Some other models might run intro context limit errors, and unexpected responses. Please provide any feedback in our <a href="https://discord.gg/DUmbTebB">Discord community</a> channel, so we can better improve the experience and performance.</p>
<p>Below you can find examples for how to configure the various supported LLMs.</p>
<h1><a class="anchor" id="autotoc_md111"></a>
Custom OpenAI</h1>
<p>Create a local OpenAI API using <a href="https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md#quick-start">llama.cpp Server</a>.</p>
<h2><a class="anchor" id="autotoc_md112"></a>
Custom OpenAI API LLM</h2>
<div class="fragment"><div class="line"># use a custom OpenAI API LLM provider</div>
<div class="line">LLM_PROVIDER=&quot;openai&quot;</div>
<div class="line"> </div>
<div class="line"># set the custom OpenAI API url</div>
<div class="line">OPENAI_BASE_URL=&quot;http://localhost:1234/v1&quot;</div>
<div class="line"># set the custom OpenAI API key</div>
<div class="line">OPENAI_API_KEY=&quot;Your Key&quot;</div>
<div class="line"> </div>
<div class="line"># specify the custom OpenAI API llm model  </div>
<div class="line">FAST_LLM_MODEL=&quot;gpt-3.5-turbo-16k&quot;</div>
<div class="line"># specify the custom OpenAI API llm model  </div>
<div class="line">SMART_LLM_MODEL=&quot;gpt-4o&quot;</div>
</div><!-- fragment --> <h2><a class="anchor" id="autotoc_md113"></a>
Custom OpenAI API Embedding</h2>
<div class="fragment"><div class="line"># use a custom OpenAI API EMBEDDING provider</div>
<div class="line">EMBEDDING_PROVIDER=&quot;custom&quot;</div>
<div class="line"> </div>
<div class="line"># set the custom OpenAI API url</div>
<div class="line">OPENAI_BASE_URL=&quot;http://localhost:1234/v1&quot;</div>
<div class="line"># set the custom OpenAI API key</div>
<div class="line">OPENAI_API_KEY=&quot;Your Key&quot;</div>
<div class="line"> </div>
<div class="line"># specify the custom OpenAI API embedding model   </div>
<div class="line">OPENAI_EMBEDDING_MODEL=&quot;custom_model&quot;</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md114"></a>
Azure OpenAI</h2>
<div class="fragment"><div class="line">EMBEDDING_PROVIDER=&quot;azureopenai&quot;</div>
<div class="line">AZURE_OPENAI_API_KEY=&quot;Your key&quot;</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md115"></a>
Ollama</h1>
<p>GPT Researcher supports both Ollama LLMs and embeddings. You can choose each or both. To use <a href="http://www.ollama.com">Ollama</a> you can set the following environment variables</p>
<div class="fragment"><div class="line"># Use ollama for both, LLM and EMBEDDING provider</div>
<div class="line">LLM_PROVIDER=ollama</div>
<div class="line"> </div>
<div class="line"># Ollama endpoint to use</div>
<div class="line">OLLAMA_BASE_URL=http://localhost:11434</div>
<div class="line"> </div>
<div class="line"># Specify one of the LLM models supported by Ollama</div>
<div class="line">FAST_LLM_MODEL=llama3</div>
<div class="line"># Specify one of the LLM models supported by Ollama </div>
<div class="line">SMART_LLM_MODEL=llama3 </div>
<div class="line"># The temperature to use, defaults to 0.55</div>
<div class="line">TEMPERATURE=0.55</div>
</div><!-- fragment --><p><b>Optional</b> - You can also use ollama for embeddings </p><div class="fragment"><div class="line">EMBEDDING_PROVIDER=ollama</div>
<div class="line"># Specify one of the embedding models supported by Ollama </div>
<div class="line">OLLAMA_EMBEDDING_MODEL=nomic-embed-text</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md116"></a>
Groq</h1>
<p>GroqCloud provides advanced AI hardware and software solutions designed to deliver amazingly fast AI inference performance. To leverage Groq in GPT-Researcher, you will need a GroqCloud account and an API Key. (<b>NOTE:</b> Groq has a very <em>generous free tier</em>.)</p>
<h2><a class="anchor" id="autotoc_md117"></a>
Sign up</h2>
<ul>
<li>You can signup here: <a href="https://console.groq.com/login">https://console.groq.com/login</a></li>
<li>Once you are logged in, you can get an API Key here: <a href="https://console.groq.com/keys">https://console.groq.com/keys</a></li>
<li>Once you have an API key, you will need to add it to your <code>systems environment</code> using the variable name: <code>GROQ_API_KEY="*********************"</code></li>
</ul>
<h2><a class="anchor" id="autotoc_md118"></a>
Update env vars</h2>
<p>And finally, you will need to configure the GPT-Researcher Provider and Model variables:</p>
<div class="fragment"><div class="line"># To use Groq set the llm provider to groq</div>
<div class="line">LLM_PROVIDER=groq</div>
<div class="line">GROQ_API_KEY=[Your Key]</div>
<div class="line"> </div>
<div class="line"># Set one of the LLM models supported by Groq</div>
<div class="line">FAST_LLM_MODEL=Mixtral-8x7b-32768</div>
<div class="line"> </div>
<div class="line"># Set one of the LLM models supported by Groq</div>
<div class="line">SMART_LLM_MODEL=Mixtral-8x7b-32768 </div>
<div class="line"> </div>
<div class="line"># The temperature to use defaults to 0.55</div>
<div class="line">TEMPERATURE=0.55</div>
</div><!-- fragment --><p><b>NOTE:</b> As of the writing of this Doc (May 2024), the available Language Models from Groq are:</p>
<ul>
<li>Llama3-70b-8192</li>
<li>Llama3-8b-8192</li>
<li>Mixtral-8x7b-32768</li>
<li>Gemma-7b-it</li>
</ul>
<h1><a class="anchor" id="autotoc_md119"></a>
Anthropic</h1>
<p><a href="https://www.anthropic.com/">Anthropic</a> is an AI safety and research company, and is the creator of Claude. This page covers all integrations between Anthropic models and LangChain.</p>
<div class="fragment"><div class="line">LLM_PROVIDER=anthropic</div>
<div class="line">ANTHROPIC_API_KEY=[Your key]</div>
</div><!-- fragment --><p>You can then define the fast and smart LLM models for example: </p><div class="fragment"><div class="line">FAST_LLM_MODEL=claude-2.1</div>
<div class="line">SMART_LLM_MODEL=claude-3-opus-20240229</div>
</div><!-- fragment --><p>You can then define the fast and smart LLM models for example: </p><div class="fragment"><div class="line">FAST_LLM_MODEL=claude-2.1</div>
<div class="line">SMART_LLM_MODEL=claude-3-opus-20240229</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md120"></a>
Mistral</h1>
<p>Sign up for a <a href="https://console.mistral.ai/users/api-keys/">Mistral API key</a>. Then update the corresponding env vars, for example: </p><div class="fragment"><div class="line">LLM_PROVIDER=mistral</div>
<div class="line">ANTHROPIC_API_KEY=[Your key]</div>
<div class="line">FAST_LLM_MODEL=open-mistral-7b</div>
<div class="line">SMART_LLM_MODEL=mistral-large-latest</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md121"></a>
Together AI</h1>
<p><a href="https://www.together.ai/">Together AI</a> offers an API to query <a href="https://docs.together.ai/docs/inference-models">50+ leading open-source models</a> in a couple lines of code. Then update corresponding env vars, for example: </p><div class="fragment"><div class="line">LLM_PROVIDER=together</div>
<div class="line">TOGETHER_API_KEY=[Your key]</div>
<div class="line">FAST_LLM_MODEL=meta-llama/Llama-3-8b-chat-hf</div>
<div class="line">SMART_LLM_MODEL=meta-llama/Llama-3-70b-chat-hf</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md122"></a>
HuggingFace</h1>
<p>This integration requires a bit of extra work. Follow <a href="https://python.langchain.com/v0.1/docs/integrations/chat/huggingface/">this guide</a> to learn more. After you've followed the tutorial above, update the env vars:</p>
<div class="fragment"><div class="line">LLM_PROVIDER=huggingface</div>
<div class="line">HUGGINGFACE_API_KEY=[Your key]</div>
<div class="line">FAST_LLM_MODEL=HuggingFaceH4/zephyr-7b-beta</div>
<div class="line">SMART_LLM_MODEL=HuggingFaceH4/zephyr-7b-beta</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md123"></a>
Google Gemini</h1>
<p>Sign up <a href="https://ai.google.dev/gemini-api/docs/api-key">here</a> for obtaining a Google Gemini API Key and update the following env vars:</p>
<p>Please make sure to update fast and smart models to corresponding valid Gemini models. </p><div class="fragment"><div class="line">LLM_PROVIDER=google</div>
<div class="line">GEMINI_API_KEY=[Your key]</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.10.0-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://penify.dev/"><img class="footer" src="https://www.penify.dev/_next/static/media/snorkell-dark-logo.9fa414f5.svg" width="104" height="31" alt="doxygen"/></a> </li>
  </ul>
</div>
</body>
</html>
